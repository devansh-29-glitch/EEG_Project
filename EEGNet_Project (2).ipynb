{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJMXHtT5gmiZ"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet mne scikit-learn seaborn pyriemann\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from scipy.signal import butter, sosfiltfilt, welch\n",
        "import joblib\n",
        "import os\n",
        "print(\"Imports done\")\n",
        "\n",
        "\n",
        "def bandpass_filter(data, sfreq, low=1.0, high=40.0, order=4):\n",
        "    sos = butter(order, [low, high], btype='band', fs=sfreq, output='sos')\n",
        "    return sosfiltfilt(sos, data, axis=-1)\n",
        "\n",
        "def bandpower(psd, freqs, band):\n",
        "    \"\"\"Compute band power from PSD (freqs, psd arrays). band=(fmin,fmax)\"\"\"\n",
        "    fmin, fmax = band\n",
        "    idx = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
        "    return np.trapz(psd[idx], freqs[idx])\n",
        "\n",
        "def epoch_to_bandpower(epochs, sfreq, bands=[(1,4),(4,8),(8,13),(13,30),(30,45)]):\n",
        "    \"\"\"\n",
        "    epochs: ndarray shape (n_epochs, n_channels, n_samples)\n",
        "    returns features shape (n_epochs, n_channels * n_bands)\n",
        "    \"\"\"\n",
        "    n_epochs, n_ch, n_samp = epochs.shape\n",
        "    feats = []\n",
        "    for e in range(n_epochs):\n",
        "        ch_feats = []\n",
        "        for ch in range(n_ch):\n",
        "            freqs, psd = welch(epochs[e,ch,:], fs=sfreq, nperseg=256)\n",
        "            for b in bands:\n",
        "                ch_feats.append(bandpower(psd, freqs, b))\n",
        "        feats.append(ch_feats)\n",
        "    return np.array(feats)\n",
        "\n",
        "print(\"Utility functions ready\")\n",
        "\n",
        "\n",
        "sfreq = 128  # Hz\n",
        "epoch_t = 1.0  # seconds per epoch\n",
        "n_samples = int(sfreq * epoch_t)\n",
        "n_channels = 16\n",
        "n_epochs = 400  # total trials\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "def make_epoch(class_label):\n",
        "    t = np.arange(n_samples) / sfreq\n",
        "    epoch = np.zeros((n_channels, n_samples))\n",
        "    for ch in range(n_channels):\n",
        "        base_noise = 0.5 * rng.normal(size=n_samples)\n",
        "        if class_label == 0:\n",
        "            sig = 1.0 * np.sin(2 * np.pi * 10 * t)  # alpha\n",
        "        else:\n",
        "            sig = 1.0 * np.sin(2 * np.pi * 20 * t)  # beta\n",
        "\n",
        "        scale = rng.uniform(0.2, 1.0)\n",
        "        epoch[ch,:] = scale * sig + base_noise\n",
        "\n",
        "    epoch += 0.05 * rng.normal(size=epoch.shape)\n",
        "    return epoch\n",
        "\n",
        "X_epochs = np.array([ make_epoch(0 if i < n_epochs//2 else 1) for i in range(n_epochs) ])\n",
        "y = np.array([0]*(n_epochs//2) + [1]*(n_epochs//2))\n",
        "print(\"Synthetic data shape:\", X_epochs.shape, \"Labels shape:\", y.shape)\n",
        "\n",
        "\n",
        "X_epochs_bp = bandpass_filter(X_epochs, sfreq, low=1.0, high=40.0)\n",
        "print(\"Bandpass applied:\", X_epochs_bp.shape)\n",
        "\n",
        "\n",
        "bands = [(1,4),(4,8),(8,13),(13,30),(30,45)]\n",
        "X_feats = epoch_to_bandpower(X_epochs_bp, sfreq, bands=bands)\n",
        "print(\"Feature matrix shape:\", X_feats.shape)  # (n_epochs, n_channels * n_bands)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_feats, y, test_size=0.2, random_state=42, stratify=y)\n",
        "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, probability=False, random_state=42))\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Baseline SVM accuracy on synthetic data: {acc*100:.2f}%\")\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix plot\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion matrix (synthetic baseline)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "joblib.dump(clf, \"artifacts/baseline_svm.joblib\")\n",
        "print(\"Model saved to artifacts/baseline_svm.joblib\")\n",
        "\n",
        "\n",
        "example_epoch = X_epochs_bp[0]  # shape (n_channels, n_samples)\n",
        "channel = 0\n",
        "freqs, psd = welch(example_epoch[channel,:], fs=sfreq, nperseg=256)\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.semilogy(freqs, psd)\n",
        "plt.xlabel(\"Frequency (Hz)\"); plt.ylabel(\"PSD\")\n",
        "plt.title(\"PSD example (synthetic, ch0)\")\n",
        "plt.xlim(0,60)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne --quiet\n",
        "\n",
        "import mne\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # select S001T001.edf from your computer\n",
        "\n",
        "\n",
        "raw = mne.io.read_raw_edf(\"S001R01.edf\", preload=True)\n",
        "print(raw.info)\n",
        "print(raw.ch_names)\n",
        "\n",
        "\n",
        "raw.plot(start=0, duration=5, n_channels=8)\n"
      ],
      "metadata": {
        "id": "CNAP0PYMkQjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sfreq = raw.info['sfreq']\n",
        "raw.filter(l_freq=1., h_freq=40.)\n",
        "raw.notch_filter(freqs=50.)\n",
        "\n",
        "\n",
        "channel_name = raw.ch_names[0]\n",
        "raw.plot_psd(fmax=60, picks=[channel_name])\n"
      ],
      "metadata": {
        "id": "r5al7MErlyW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "epoch_length_sec = 2\n",
        "sfreq = raw.info['sfreq']\n",
        "epoch_length_samples = int(epoch_length_sec * sfreq)\n",
        "\n",
        "\n",
        "data = raw.get_data()  # shape: (n_channels, n_times)\n",
        "n_channels, n_times = data.shape\n",
        "\n",
        "\n",
        "n_epochs = n_times // epoch_length_samples\n",
        "\n",
        "\n",
        "pseudo_epochs = np.array([data[:, i*epoch_length_samples:(i+1)*epoch_length_samples].T\n",
        "                          for i in range(n_epochs)])\n",
        "print(\"Pseudo-epochs shape:\", pseudo_epochs.shape)  # (n_epochs, n_samples, n_channels)\n"
      ],
      "metadata": {
        "id": "hgfHUmBvpLwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import welch\n",
        "\n",
        "# Function to compute band-power\n",
        "def bandpower(psd, freqs, band):\n",
        "    fmin, fmax = band\n",
        "    idx = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
        "    return np.trapz(psd[idx], freqs[idx])\n",
        "\n",
        "# Convert pseudo-epochs to feature matrix\n",
        "def pseudo_epochs_to_features(pseudo_epochs, sfreq, bands=[(1,4),(4,8),(8,13),(13,30)]):\n",
        "    n_epochs, n_samples, n_channels = pseudo_epochs.shape\n",
        "    feats = []\n",
        "    for e in range(n_epochs):\n",
        "        ch_feats = []\n",
        "        for ch in range(n_channels):\n",
        "            freqs, psd = welch(pseudo_epochs[e,:,ch], fs=sfreq, nperseg=128)\n",
        "            for b in bands:\n",
        "                ch_feats.append(bandpower(psd, freqs, b))\n",
        "        feats.append(ch_feats)\n",
        "    return np.array(feats)\n",
        "\n",
        "# Extract features\n",
        "X_features = pseudo_epochs_to_features(pseudo_epochs, sfreq)\n",
        "print(\"Feature matrix shape:\", X_features.shape)\n"
      ],
      "metadata": {
        "id": "xwoMShtjtPgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "y_labels = np.array([i%2 for i in range(X_features.shape[0])])\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y_labels)\n",
        "\n",
        "# Train baseline SVM\n",
        "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, random_state=42))\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Accuracy & report\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Baseline SVM accuracy on pseudo-epochs: {acc*100:.2f}%\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix (graphical)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion matrix (pseudo-epochs)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MksAK8EGtdGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --quiet"
      ],
      "metadata": {
        "id": "rNnhlX0zt92Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(n_epochs, n_channels, n_samples)\n"
      ],
      "metadata": {
        "id": "n2UjQel5uPhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Reorder pseudo-epochs: (epochs, samples, channels) -> (epochs, channels, samples)\n",
        "X = np.transpose(pseudo_epochs, (0, 2, 1)).astype(np.float32)  # shape: (30, 64, 320)\n",
        "y = y_labels.astype(np.int64)  # shape: (30,)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X)\n",
        "y_tensor = torch.tensor(y)\n",
        "\n",
        "# Create dataset & dataloaders\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "print(\"Training samples:\", len(train_dataset))\n",
        "print(\"Testing samples:\", len(test_dataset))\n"
      ],
      "metadata": {
        "id": "qcH77RG9uRY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGNet(nn.Module):\n",
        "    def __init__(self, n_channels=64, n_samples=320, n_classes=2):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, (1, 64))\n",
        "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, (n_channels,1))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.pool = nn.AvgPool2d((1,4))\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "\n",
        "        self.fc = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # add channel dim: (batch, 1, channels, samples)\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "\n",
        "\n",
        "        if self.fc is None:\n",
        "            self.fc = nn.Linear(x.size(1), self.n_classes).to(x.device)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "vM7xOFRyud0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EEGNet(n_channels=64, n_samples=320, n_classes=2)\n"
      ],
      "metadata": {
        "id": "PDriCqIYvjGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 50\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "AghTyh39wWWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to evaluation mode\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_true.extend(y_batch.numpy())\n",
        "        y_pred.extend(preds.numpy())\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"EEGNet accuracy on pseudo-epochs: {acc*100:.2f}%\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"EEGNet Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UudUgs0JwjTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Average PSD across all pseudo-epochs for first 8 channels\n",
        "n_channels_to_plot = 8\n",
        "plt.figure(figsize=(15,8))\n",
        "for ch in range(n_channels_to_plot):\n",
        "    psd_ch = []\n",
        "    for epoch in pseudo_epochs:\n",
        "        freqs, psd = plt.psd(epoch[:, ch], NFFT=128, Fs=sfreq)\n",
        "        psd_ch.append(psd)\n",
        "    avg_psd = np.mean(psd_ch, axis=0)\n",
        "    plt.plot(freqs, avg_psd, label=f'Channel {ch+1}')\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power Spectral Density\")\n",
        "plt.title(\"Average PSD across pseudo-epochs (first 8 channels)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9KaGIROtygJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple way: average absolute activation before fully connected layer\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_tensor_batch = X_tensor  # all pseudo-epochs\n",
        "    x = X_tensor_batch.unsqueeze(1)  # add channel dim\n",
        "    x = model.conv1(x)\n",
        "    x = model.batchnorm1(x)\n",
        "    x = model.relu(x)\n",
        "    x = model.conv2(x)\n",
        "    x = model.batchnorm2(x)\n",
        "    x = model.relu(x)\n",
        "    x = model.pool(x)\n",
        "    activations = x.mean(dim=0).squeeze()  # mean across samples\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.imshow(activations.numpy(), aspect='auto', cmap='viridis')\n",
        "plt.colorbar(label=\"Activation magnitude\")\n",
        "plt.xlabel(\"Time / Pool index\")\n",
        "plt.ylabel(\"Feature maps\")\n",
        "plt.title(\"EEGNet Activation Heatmap (averaged across pseudo-epochs)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xSXG7OnMymUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Example: accuracies from previous steps\n",
        "baseline_acc = 50  # SVM baseline %\n",
        "eegnet_acc = acc*100  # from Step 4d\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.barplot(x=['Baseline SVM', 'EEGNet'], y=[baseline_acc, eegnet_acc])\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Comparison: Baseline ML vs Deep Learning\")\n",
        "plt.ylim(0,100)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HM1maoYUypYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a random pseudo-epoch\n",
        "new_epoch = torch.tensor(pseudo_epochs[0].T).unsqueeze(0).float()  # shape: (1,64,320)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(new_epoch)\n",
        "    pred_class = torch.argmax(output, dim=1).item()\n",
        "print(f\"Predicted class for new pseudo-epoch: {pred_class}\")\n"
      ],
      "metadata": {
        "id": "xnjKQrihyy4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "raw_list = []\n",
        "for filename in uploaded_files.keys():\n",
        "    raw = mne.io.read_raw_edf(filename, preload=True)\n",
        "    raw_list.append(raw)\n",
        "\n",
        "print(f\"Loaded {len(raw_list)} subjects/trials\")\n"
      ],
      "metadata": {
        "id": "YmqbcNXZ8s9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pseudo_epochs = []\n",
        "\n",
        "epoch_length_sec = 2\n",
        "\n",
        "for raw in raw_list:\n",
        "    sfreq = raw.info['sfreq']\n",
        "    epoch_length_samples = int(epoch_length_sec * sfreq)\n",
        "    data = raw.get_data()  # (channels, times)\n",
        "    n_channels, n_times = data.shape\n",
        "    n_epochs = n_times // epoch_length_samples\n",
        "    pseudo_epochs = np.array([data[:, i*epoch_length_samples:(i+1)*epoch_length_samples].T\n",
        "                              for i in range(n_epochs)])\n",
        "    all_pseudo_epochs.append(pseudo_epochs)\n",
        "\n",
        "\n",
        "combined_pseudo_epochs = np.vstack(all_pseudo_epochs)\n",
        "print(\"Combined pseudo-epochs shape:\", combined_pseudo_epochs.shape)\n"
      ],
      "metadata": {
        "id": "HM0BLNFi-7W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_epochs_total = combined_pseudo_epochs.shape[0]\n",
        "y_labels_combined = np.array([i%2 for i in range(n_epochs_total)])\n",
        "print(\"Labels shape:\", y_labels_combined.shape)\n"
      ],
      "metadata": {
        "id": "9hiLoB0C-_55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def predict_new_epoch(model, epoch):\n",
        "    \"\"\"\n",
        "    epoch: shape (samples, channels) e.g. (320, 64)\n",
        "    model: trained EEGNet model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.tensor(epoch.T, dtype=torch.float32)\n",
        "        x = x.unsqueeze(0)\n",
        "        output = model(x)\n",
        "        predicted_class = torch.argmax(output, dim=1).item()\n",
        "    return predicted_class\n"
      ],
      "metadata": {
        "id": "UHenVapk_azS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Simulate a pseudo-epoch from existing data\n",
        "new_epoch = combined_pseudo_epochs[0]  # just take first epoch for demo\n",
        "\n",
        "\n",
        "\n",
        "predicted = predict_new_epoch(model, new_epoch)\n",
        "print(f\"Predicted class for new pseudo-epoch: {predicted}\")\n"
      ],
      "metadata": {
        "id": "rkHkJI5D_fw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "conv1_weights = model.conv1.weight.detach().cpu().numpy()  # (16,1,1,64)\n",
        "\n",
        "\n",
        "channel_importance = np.mean(np.abs(conv1_weights), axis=0).flatten()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.bar(range(1, 65), channel_importance)\n",
        "plt.xlabel(\"EEG Channel\")\n",
        "plt.ylabel(\"Average absolute weight\")\n",
        "plt.title(\"EEG Channel Importance (Conv1)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hF-x7zJ2_0xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model.eval()\n",
        "x = torch.tensor(new_epoch.T, dtype=torch.float32).unsqueeze(0)  # (1, 64, 320)\n",
        "x = x.unsqueeze(1)  # (1,1,64,320)\n",
        "\n",
        "with torch.no_grad():\n",
        "    activations = model.relu(model.batchnorm1(model.conv1(x)))\n",
        "\n",
        "\n",
        "activations_np = activations.squeeze(0).mean(axis=0).numpy()\n",
        "\n",
        "# Plot heatmap: channels vs time\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(activations_np, aspect='auto', cmap='viridis')\n",
        "plt.colorbar(label=\"Activation magnitude\")\n",
        "plt.xlabel(\"Time Samples\")\n",
        "plt.ylabel(\"Channels\")\n",
        "plt.title(\"EEGNet Conv1 Activation Map (Mean over Filters)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cQarhbFJ_9rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For demonstration, simulate SVM predictions (baseline)\n",
        "svm_preds = np.random.randint(0, 2, size=y_labels_combined.shape[0])\n",
        "eegnet_preds = torch.argmax(model(torch.tensor(combined_pseudo_epochs.transpose(0,2,1), dtype=torch.float32)), dim=1).numpy()\n",
        "\n",
        "# Count correct predictions for both models\n",
        "svm_acc = np.mean(svm_preds == y_labels_combined)\n",
        "eegnet_acc = np.mean(eegnet_preds == y_labels_combined)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(['SVM', 'EEGNet'], [svm_acc, eegnet_acc], color=['gray', 'teal'])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Comparison on Multi-Subject Pseudo-Epochs\")\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zSkwkQF8ADw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets --quiet\n",
        "from ipywidgets import interact, IntSlider, Dropdown\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "JhMDtk7DA1sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_demo(epoch_index, show_activation=True):\n",
        "    \"\"\"\n",
        "    epoch_index: integer index of pseudo-epoch\n",
        "    show_activation: whether to plot activation heatmap\n",
        "    \"\"\"\n",
        "\n",
        "    selected_epoch = combined_pseudo_epochs[epoch_index]\n",
        "\n",
        "    # Predict\n",
        "    pred_class = predict_new_epoch(model, selected_epoch)\n",
        "    print(f\"Pseudo-epoch #{epoch_index} predicted class: {pred_class}\")\n",
        "\n",
        "    # Plot activation map\n",
        "    if show_activation:\n",
        "        x = torch.tensor(selected_epoch.T, dtype=torch.float32).unsqueeze(0).unsqueeze(1)\n",
        "        with torch.no_grad():\n",
        "            activations = model.relu(model.batchnorm1(model.conv1(x)))\n",
        "        activations_np = activations.squeeze(0).mean(axis=0).numpy()\n",
        "\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.imshow(activations_np, aspect='auto', cmap='viridis')\n",
        "        plt.colorbar(label=\"Activation magnitude\")\n",
        "        plt.xlabel(\"Time Samples\")\n",
        "        plt.ylabel(\"Channels\")\n",
        "        plt.title(f\"Activation Map for Pseudo-epoch #{epoch_index}\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "5Lrdbm1GBB3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interact(interactive_demo,\n",
        "         epoch_index=IntSlider(min=0, max=combined_pseudo_epochs.shape[0]-1, step=1, value=0),\n",
        "         show_activation=True)\n"
      ],
      "metadata": {
        "id": "78SuzPfWBFRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}